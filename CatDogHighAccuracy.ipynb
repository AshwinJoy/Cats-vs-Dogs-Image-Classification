{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats vs Dogs Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifying images of dogs and cats using deep learning with keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing needed libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Activation,MaxPooling2D,Dense,Flatten,Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding convolutional layer which does filtering\n",
    "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3))) \n",
    "#32 is the no.of filters. the filter is an array of numbers, (3,3) is the size of the filter.\n",
    "#The input image is 64*64*3 size #64 height and 64 width and 3 refers RGB values\n",
    "#Each of the numbers in this array(64,64,3) is given values from 0 to 255 \n",
    "#which describes the pixel intensity at that point. \n",
    "#The output of this layer will be some feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Let's pass the feature maps through an activation layer called ReLu\n",
    "classifier.add(Activation('relu'))\n",
    "#ReLu replaces all the negative pixel values in the feature map with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size =(2,2)))\n",
    "#Pooling reduces the dimensionality of each feature map, but retains the most imp. info.\n",
    "#This reduces the computational complexity of our network\n",
    "#Here, we used maxpooling with 2*2 filter. the filter will take the max values from each pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A classic CNN has 3 Convolutional blocks followed by a fully connected layer.\n",
    "#we created the first set of layers. We can repeat this twice more.\n",
    "classifier.add(Conv2D(32,(3,3))) \n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(MaxPooling2D(pool_size =(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One more....\n",
    "classifier.add(Conv2D(64,(3,3))) \n",
    "classifier.add(Activation('relu'))\n",
    "classifier.add(MaxPooling2D(pool_size =(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prevent overfitting, we use dropout layer.\n",
    "#This layer drops out a random set of activations in that layer by setting them to zero as data flows through it.\n",
    "#To prepare our model for droupot, we first flatten the feature map to 1D.\n",
    "classifier.add(Flatten())\n",
    "#Then we want to initialize a fully connected nw by Dense function\n",
    "classifier.add(Dense(64))\n",
    "# and apply relu to it.\n",
    "classifier.add(Activation('relu'))\n",
    "#Add the Dropout layer\n",
    "classifier.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After dropout, we'll initialize 1 more fully connected layer.\n",
    "#This will output an n D vector, where n is the no.of classes we have, that is 2.\n",
    "classifier.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 176,225\n",
      "Trainable params: 176,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#By applying a sigmoid to it, it'll convert the data to probabilities for each class.\n",
    "classifier.add(Activation('sigmoid'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling cnn\n",
    "classifier.compile(optimizer ='rmsprop',\n",
    "                   loss ='binary_crossentropy',\n",
    "                   metrics =['accuracy'])\n",
    "#Optimizer rmsprop will perform gradient descent(finding the min. of a function)\n",
    "#binary_crossentropy is the prefered loss fn for binary classif. problems\n",
    "#metrics is set to accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing overfitting by data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale =1./255,\n",
    "                                   shear_range =0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip =True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Setting Train and Test directories\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/Lab/Desktop/CatDogData/train',\n",
    "                                                target_size=(64,64),\n",
    "                                                batch_size= 32,\n",
    "                                                class_mode='binary')\n",
    "#and..\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/Lab/Desktop/CatDogData/test',\n",
    "                                           target_size = (64,64),\n",
    "                                           batch_size = 32,\n",
    "                                           class_mode ='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 [==============================] - 1306s 2s/step - loss: 0.6294 - acc: 0.6383 - val_loss: 0.5183 - val_acc: 0.7440\n",
      "Epoch 2/30\n",
      "625/625 [==============================] - 1005s 2s/step - loss: 0.5435 - acc: 0.7274 - val_loss: 0.4935 - val_acc: 0.7603\n",
      "Epoch 3/30\n",
      "625/625 [==============================] - 999s 2s/step - loss: 0.4953 - acc: 0.7651 - val_loss: 0.4352 - val_acc: 0.7934\n",
      "Epoch 4/30\n",
      "625/625 [==============================] - 1014s 2s/step - loss: 0.4644 - acc: 0.7832 - val_loss: 0.7301 - val_acc: 0.7150\n",
      "Epoch 5/30\n",
      "625/625 [==============================] - 1150s 2s/step - loss: 0.4459 - acc: 0.7957 - val_loss: 0.3825 - val_acc: 0.8326\n",
      "Epoch 6/30\n",
      "625/625 [==============================] - 1214s 2s/step - loss: 0.4320 - acc: 0.8019 - val_loss: 0.4102 - val_acc: 0.8139\n",
      "Epoch 7/30\n",
      "625/625 [==============================] - 1201s 2s/step - loss: 0.4198 - acc: 0.8141 - val_loss: 0.3975 - val_acc: 0.8263\n",
      "Epoch 8/30\n",
      "625/625 [==============================] - 1453s 2s/step - loss: 0.4091 - acc: 0.8212 - val_loss: 0.4358 - val_acc: 0.8072\n",
      "Epoch 9/30\n",
      "625/625 [==============================] - 1178s 2s/step - loss: 0.3980 - acc: 0.8237 - val_loss: 0.3789 - val_acc: 0.8244\n",
      "Epoch 10/30\n",
      "625/625 [==============================] - 1180s 2s/step - loss: 0.3889 - acc: 0.8327 - val_loss: 0.3462 - val_acc: 0.8488\n",
      "Epoch 11/30\n",
      "625/625 [==============================] - 1179s 2s/step - loss: 0.3921 - acc: 0.8293 - val_loss: 0.3556 - val_acc: 0.8523\n",
      "Epoch 12/30\n",
      "625/625 [==============================] - 1181s 2s/step - loss: 0.3814 - acc: 0.8356 - val_loss: 0.3529 - val_acc: 0.8554\n",
      "Epoch 13/30\n",
      "625/625 [==============================] - 1169s 2s/step - loss: 0.3779 - acc: 0.8362 - val_loss: 0.4392 - val_acc: 0.8194\n",
      "Epoch 14/30\n",
      "625/625 [==============================] - 1177s 2s/step - loss: 0.3763 - acc: 0.8381 - val_loss: 0.3652 - val_acc: 0.8452\n",
      "Epoch 15/30\n",
      "625/625 [==============================] - 1028s 2s/step - loss: 0.3686 - acc: 0.8397 - val_loss: 0.3401 - val_acc: 0.8543\n",
      "Epoch 16/30\n",
      "625/625 [==============================] - 945s 2s/step - loss: 0.3677 - acc: 0.8448 - val_loss: 0.4367 - val_acc: 0.7985\n",
      "Epoch 17/30\n",
      "625/625 [==============================] - 2088s 3s/step - loss: 0.3634 - acc: 0.8433 - val_loss: 0.3318 - val_acc: 0.8556\n",
      "Epoch 18/30\n",
      "625/625 [==============================] - 952s 2s/step - loss: 0.3610 - acc: 0.8470 - val_loss: 0.3281 - val_acc: 0.8566\n",
      "Epoch 19/30\n",
      "625/625 [==============================] - 943s 2s/step - loss: 0.3603 - acc: 0.8479 - val_loss: 0.5352 - val_acc: 0.7698\n",
      "Epoch 20/30\n",
      "625/625 [==============================] - 1237s 2s/step - loss: 0.3558 - acc: 0.8478 - val_loss: 0.3360 - val_acc: 0.8518\n",
      "Epoch 21/30\n",
      "625/625 [==============================] - 948s 2s/step - loss: 0.3541 - acc: 0.8488 - val_loss: 0.3456 - val_acc: 0.8488\n",
      "Epoch 22/30\n",
      "625/625 [==============================] - 3800s 6s/step - loss: 0.3599 - acc: 0.8476 - val_loss: 0.3336 - val_acc: 0.8592\n",
      "Epoch 23/30\n",
      "625/625 [==============================] - 1283s 2s/step - loss: 0.3568 - acc: 0.8505 - val_loss: 0.3099 - val_acc: 0.8697\n",
      "Epoch 24/30\n",
      "625/625 [==============================] - 1194s 2s/step - loss: 0.3543 - acc: 0.8479 - val_loss: 0.3103 - val_acc: 0.8646\n",
      "Epoch 25/30\n",
      "625/625 [==============================] - 1638s 3s/step - loss: 0.3509 - acc: 0.8528 - val_loss: 0.3153 - val_acc: 0.8626\n",
      "Epoch 26/30\n",
      "625/625 [==============================] - 1317s 2s/step - loss: 0.3473 - acc: 0.8520 - val_loss: 0.3174 - val_acc: 0.8726\n",
      "Epoch 27/30\n",
      "625/625 [==============================] - 1142s 2s/step - loss: 0.3551 - acc: 0.8508 - val_loss: 0.3444 - val_acc: 0.8662\n",
      "Epoch 28/30\n",
      "625/625 [==============================] - 1534s 2s/step - loss: 0.3474 - acc: 0.8543 - val_loss: 0.3737 - val_acc: 0.8556\n",
      "Epoch 29/30\n",
      "625/625 [==============================] - 1187s 2s/step - loss: 0.3484 - acc: 0.8555 - val_loss: 0.3320 - val_acc: 0.8687\n",
      "Epoch 30/30\n",
      "625/625 [==============================] - 1196s 2s/step - loss: 0.3512 - acc: 0.8531 - val_loss: 0.4720 - val_acc: 0.8373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x184a75219b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                        steps_per_epoch =625,\n",
    "                        epochs = 30,\n",
    "                        validation_data =test_set,\n",
    "                        validation_steps = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model \n",
    "classifier.save('catdog_model.h5') # creates a HDF5 file 'catdog_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "#loading the saved model\n",
    "from keras.models import load_model \n",
    "classifier = load_model('catdog_model.h5')\n",
    "\n",
    "#testing\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "img = image.load_img('C:/Users/Lab/Desktop/CatDogData/predict/d1.jpeg', target_size=(64,64))\n",
    "img = np.array(img)\n",
    "img =np.expand_dims(img, axis =0)\n",
    "prediction = classifier.predict(img)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#testing\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image =image.load_img('C:/Users/Lab/image.jpeg',target_size =(64,64))\n",
    "test_image =image.img_to_array(test_image)\n",
    "test_image =np.expand_dims(test_image, axis =0)\n",
    "result = classifier.predict(test_image)\n",
    "if result[0][0] >= 0.5:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
